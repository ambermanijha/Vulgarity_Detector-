{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------\n",
      "absl-py                      2.1.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "certifi                      2024.6.2\n",
      "charset-normalizer           3.3.2\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.2\n",
      "contourpy                    1.2.1\n",
      "cycler                       0.12.1\n",
      "debugpy                      1.8.2\n",
      "decorator                    5.1.1\n",
      "exceptiongroup               1.2.0\n",
      "executing                    2.0.1\n",
      "flatbuffers                  24.3.25\n",
      "fonttools                    4.53.0\n",
      "gast                         0.6.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.64.1\n",
      "h5py                         3.11.0\n",
      "idna                         3.7\n",
      "importlib_metadata           8.0.0\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.26.0\n",
      "jedi                         0.19.1\n",
      "jupyter_client               8.6.2\n",
      "jupyter_core                 5.7.2\n",
      "keras                        3.4.1\n",
      "kiwisolver                   1.4.5\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.6\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib                   3.9.0\n",
      "matplotlib-inline            0.1.7\n",
      "mdurl                        0.1.2\n",
      "ml-dtypes                    0.3.2\n",
      "namex                        0.0.8\n",
      "nest_asyncio                 1.6.0\n",
      "numpy                        1.26.4\n",
      "opencv-python                4.10.0.84\n",
      "opt-einsum                   3.3.0\n",
      "optree                       0.11.0\n",
      "packaging                    24.1\n",
      "pandas                       2.2.2\n",
      "parso                        0.8.4\n",
      "pickleshare                  0.7.5\n",
      "pillow                       10.4.0\n",
      "pip                          24.0\n",
      "platformdirs                 4.2.2\n",
      "prompt_toolkit               3.0.47\n",
      "protobuf                     4.25.3\n",
      "psutil                       6.0.0\n",
      "pure-eval                    0.2.2\n",
      "pydicom                      2.4.4\n",
      "Pygments                     2.18.0\n",
      "pyparsing                    3.1.2\n",
      "python-dateutil              2.9.0\n",
      "pytz                         2024.1\n",
      "pywin32                      306\n",
      "pyzmq                        26.0.3\n",
      "requests                     2.32.3\n",
      "rich                         13.7.1\n",
      "setuptools                   69.5.1\n",
      "six                          1.16.0\n",
      "stack-data                   0.6.2\n",
      "tensorboard                  2.16.2\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.16.2\n",
      "tensorflow-intel             2.16.2\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.4.0\n",
      "tornado                      6.4.1\n",
      "traitlets                    5.14.3\n",
      "typing_extensions            4.12.2\n",
      "tzdata                       2024.1\n",
      "urllib3                      2.2.2\n",
      "wcwidth                      0.2.13\n",
      "Werkzeug                     3.0.3\n",
      "wheel                        0.43.0\n",
      "wrapt                        1.16.0\n",
      "zipp                         3.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\gore\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\nudity\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\violence\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\vulgar\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\gore\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\nudity\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\violence\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\vulgar\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\gore\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\nudity\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\violence\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\vulgar\n"
     ]
    }
   ],
   "source": [
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\test\\gore: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\test\\\\gore'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\test\\nudity: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\test\\\\nudity'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\test\\violence: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\test\\\\violence'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\test\\vulgar: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\test\\\\vulgar'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\train\\gore: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\train\\\\gore'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\train\\nudity: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\train\\\\nudity'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\train\\violence: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\train\\\\violence'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\train\\vulgar: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\train\\\\vulgar'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\val\\gore: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\val\\\\gore'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\val\\nudity: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\val\\\\nudity'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\val\\violence: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\val\\\\violence'\n",
      "Issue with image C:\\datasets_no_onedrive\\vulgarity_dataset\\val\\vulgar: [Errno 13] Permission denied: 'C:\\\\datasets_no_onedrive\\\\vulgarity_dataset\\\\val\\\\vulgar'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imghdr\n",
    "\n",
    "data_dir = r\"C:\\datasets_no_onedrive\\vulgarity_dataset\"\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, image_class)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    for image in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image)\n",
    "        try:\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip is None:\n",
    "                print(f'Image is corrupted or has an unknown format: {image_path}')\n",
    "                os.remove(image_path)\n",
    "            elif tip not in image_exts:\n",
    "                print(f'Image not in ext list: {image_path}')\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(f'Issue with image {image_path}: {e}')\n",
    "            # Optionally, you can remove the image or handle the exception as needed\n",
    "            # os.remove(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 620 files belonging to 4 classes.\n",
      "Found 76 files belonging to 4 classes.\n",
      "Found 66 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data_train_path = r'vulgarity_dataset/train'\n",
    "data_test_path = r'vulgarity_dataset/test'\n",
    "data_val_path = r'vulgarity_dataset/val'\n",
    "\n",
    "img_width = 180\n",
    "img_height =180 \n",
    "\n",
    "def create_dataset(path, batch_size=32, shuffle=True):\n",
    "    try:\n",
    "        return tf.keras.utils.image_dataset_from_directory(\n",
    "            path,\n",
    "            shuffle=shuffle,\n",
    "            image_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            validation_split=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "data_train = create_dataset(data_train_path)\n",
    "data_val = create_dataset(data_val_path, shuffle=False)\n",
    "data_test = create_dataset(data_test_path, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\gore\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\nudity\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\violence\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\test\\vulgar\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\gore\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\nudity\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\violence\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\train\\vulgar\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\gore\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\nudity\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\violence\n",
      "Issue with image C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\\val\\vulgar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imghdr\n",
    "\n",
    "data_dir = r\"C:\\Users\\amber\\OneDrive\\Desktop\\Mishka\\Vulgarity_Detection_System\\vulgarity_dataset\"\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n",
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip is None:\n",
    "                print('Image is corrupted or has an unknown format: {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "            elif tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import imghdr\n",
    "\n",
    "class ImageLoader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data_dir, image_size, batch_size):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for image_class in os.listdir(data_dir):\n",
    "            for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "                image_path = os.path.join(data_dir, image_class, image)\n",
    "                tip = imghdr.what(image_path)\n",
    "                if tip in ['jpeg', 'jpg', 'bmp', 'png']:\n",
    "                    self.image_paths.append(image_path)\n",
    "                    self.labels.append(image_class)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_image_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_images = []\n",
    "        for image_path in batch_image_paths:\n",
    "            img = tf.io.read_file(image_path)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, self.image_size)\n",
    "            batch_images.append(img)\n",
    "\n",
    "        batch_images = tf.stack(batch_images)\n",
    "        batch_labels = tf.stack(batch_labels)\n",
    "\n",
    "        return batch_images, batch_labels\n",
    "\n",
    "data_loader = ImageLoader(data_train_path, (img_width, img_height), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = r'vulgarity_dataset/train'\n",
    "data_test_path = r'vulgarity_dataset/test'\n",
    "data_val_path = r'vulgarity_dataset/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 180\n",
    "img_height =180 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 620 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_train_path,\n",
    "    shuffle=True,\n",
    "    image_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    validation_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gore', 'nudity', 'violence', 'vulgar']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data_val = tf.keras.utils.image_dataset_from_directory(data_val_path,\n",
    "                                                       image_size=(img_height,img_width),\n",
    "                                                       batch_size=32,\n",
    "                                                        shuffle=False,\n",
    "                                                       validation_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data_test = tf.keras.utils.image_dataset_from_directory(\n",
    "data_test_path,\n",
    "    image_size=(img_height,img_width),\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for image, labels in data_train.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(image[i].numpy().astype('uint8'))\n",
    "        plt.title(data_cat[labels[i]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32,3, padding='same',activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128),\n",
    "    layers.Dense(len(data_cat))\n",
    "                  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30976</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30976</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,965,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30976\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30976\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m3,965,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,989,156</span> (15.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,989,156\u001b[0m (15.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,989,156</span> (15.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,989,156\u001b[0m (15.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/Cast defined at (most recent call last):\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\amber\\AppData\\Local\\Temp\\ipykernel_15772\\2835821365.py\", line 2, in <module>\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 318, in fit\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 357, in _compute_loss\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 325, in compute_loss\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 609, in __call__\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 645, in call\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 39, in __call__\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\tree\\tree_api.py\", line 148, in map_structure\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\tree\\optree_impl.py\", line 79, in map_structure\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\optree\\ops.py\", line 594, in tree_map\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 40, in <lambda>\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\ops\\core.py\", line 743, in convert_to_tensor\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py\", line 120, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/sparse_categorical_crossentropy/Cast}}]] [Op:__inference_one_step_on_iterator_3096]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/Cast defined at (most recent call last):\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\amber\\AppData\\Local\\Temp\\ipykernel_15772\\2835821365.py\", line 2, in <module>\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 318, in fit\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 357, in _compute_loss\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 325, in compute_loss\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 609, in __call__\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 645, in call\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 39, in __call__\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\tree\\tree_api.py\", line 148, in map_structure\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\tree\\optree_impl.py\", line 79, in map_structure\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\optree\\ops.py\", line 594, in tree_map\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 40, in <lambda>\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\ops\\core.py\", line 743, in convert_to_tensor\n\n  File \"c:\\Users\\amber\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py\", line 120, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/sparse_categorical_crossentropy/Cast}}]] [Op:__inference_one_step_on_iterator_3096]"
     ]
    }
   ],
   "source": [
    "epochs_size = 25\n",
    "history = model.fit(data_loader, epochs=epochs_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
